{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelBinarizer\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m class_weight\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the annotations CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv('../input/aquatrash/annotations.csv')\n",
    "\n",
    "# Setting the path to the directory containing the images for the task\n",
    "imagefolder = '../input/aquatrash/Images'\n",
    "\n",
    "# Extracting the unique class names from the 'class_name' column of the DataFrame\n",
    "classes = np.unique(df['class_name'])\n",
    "\n",
    "\n",
    "# Taking a look at data distribution\n",
    "df['class_name'].value_counts()\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(df['class_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights based on the distribution of classes in the dataset\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(df['class_name']), y=df['class_name'])\n",
    "# Convert the class weights to a dictionary format\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "# Print the class weights\n",
    "print(class_weights_dict)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    # Initialize lists to store images, coordinates, and labels\n",
    "    images = []\n",
    "    coords = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for row in data.iloc:\n",
    "        # Extract the image filename, bounding box coordinates, and label from the row\n",
    "        image_name, start_x, start_y, end_x, end_y, label = row\n",
    "        \n",
    "        # Load the image and resize it to (224, 224)\n",
    "        image = tf.keras.utils.load_img(f'{imagefolder}/{image_name}')\n",
    "        image = tf.keras.utils.img_to_array(image)\n",
    "        height, width = image.shape[:2]\n",
    "        image = tf.image.resize(image, (224, 224))\n",
    "        \n",
    "        # Convert bounding box coordinates to absolute values\n",
    "        abs_start_x = float(start_x) / width\n",
    "        abs_start_y = float(start_y) / height\n",
    "        abs_end_x = float(end_x) / width\n",
    "        abs_end_y = float(end_y) / height\n",
    "        \n",
    "        # Append the image, coordinates, and label to their respective lists\n",
    "        images.append(image)\n",
    "        coords.append((abs_start_x, abs_start_y, abs_end_x, abs_end_y))\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Convert the images, coordinates, and labels to NumPy arrays\n",
    "    images = np.array(images, dtype='float32') / 255\n",
    "    coords = np.array(coords, dtype='float32')\n",
    "    labels = label_binarizer.transform(labels)\n",
    "    \n",
    "    return images, coords, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG19 model with pre-trained weights, excluding the top classification layer\n",
    "vgg = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Set the pre-trained weights of the VGG19 model to be non-trainable\n",
    "vgg.trainable = True\n",
    "\n",
    "# Create a flatten layer to convert the output of the VGG19 model to a 1D tensor\n",
    "flatten = Flatten()(vgg.output)\n",
    "\n",
    "# Create a branch for bounding box regression\n",
    "bbox = Dropout(0.5)(flatten)\n",
    "bbox = Dense(512, activation='relu')(bbox)\n",
    "bbox = Dense(128, activation='relu')(bbox)\n",
    "bbox = Dropout(0.5)(bbox)\n",
    "bbox_result = Dense(4, activation='sigmoid', name='bbox_result')(bbox)\n",
    "\n",
    "# Create a branch for classification\n",
    "label = Dropout(0.5)(flatten)\n",
    "label = Dense(512, activation='relu')(label)\n",
    "label = Dense(256, activation='relu')(label)\n",
    "label = Dropout(0.5)(label)\n",
    "label_result = Dense(len(label_binarizer.classes_), activation='softmax', name='label_result')(label)\n",
    "\n",
    "# Create a Keras model that takes an input image and outputs both the bounding box and label predictions\n",
    "model = Model(vgg.input, [bbox_result, label_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions for each output branch of the model\n",
    "losses = {\n",
    "    \"label_result\": \"categorical_crossentropy\",\n",
    "    \"bbox_result\": \"mean_squared_error\",\n",
    "}\n",
    "\n",
    "# Set the weight of each output branch in the overall loss function\n",
    "loss_weights = {\n",
    "    \"label_result\": 1.0,\n",
    "    \"bbox_result\": 1.0\n",
    "}\n",
    "\n",
    "# Compile the model with the defined loss functions, optimizer, and evaluation metrics\n",
    "model.compile(loss=losses, optimizer=Adam(0.00007), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the prepare_data function with the train_data input and assign the outputs to variables\n",
    "train_images, train_coords, train_labels = prepare_data(train_data)\n",
    "\n",
    "# Call the prepare_data function with the test_data input and assign the outputs to variables\n",
    "test_images, test_coords, test_labels = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of training targets with label_result and bbox_result keys,\n",
    "# and corresponding values of train_labels and train_coords\n",
    "train_targets = {\n",
    "    \"label_result\": train_labels,\n",
    "    \"bbox_result\": train_coords,\n",
    "}\n",
    "\n",
    "# Create a dictionary of test targets with label_result and bbox_result keys,\n",
    "# and corresponding values of test_labels and test_coords\n",
    "test_targets = {\n",
    "    \"label_result\": test_labels,\n",
    "    \"bbox_result\": test_coords,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model\n",
    "history = model.fit(\n",
    "    train_images, train_targets,\n",
    "    validation_data=(test_images, test_targets),\n",
    "    epochs=80,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "# Plot the training loss for the bounding box regression and classification separately\n",
    "plt.plot(history.history['bbox_result_loss'], label='bbox_loss')\n",
    "plt.plot(history.history['label_result_loss'], label='label_loss')\n",
    "\n",
    "# Plot the validation loss for the bounding box regression and classification separately\n",
    "plt.plot(history.history['val_bbox_result_loss'], label='bbox_loss_val')\n",
    "plt.plot(history.history['val_label_result_loss'], label='label_loss_val')\n",
    "\n",
    "# Add a legend to the plot and show it\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images, valid_coords, valid_labels = prepare_data(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(box_pred, label_pred) = model.predict(valid_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a figure with a size of 40x20 inches\n",
    "plt.figure(figsize=(40, 20))\n",
    "\n",
    "# Loop through 8 images\n",
    "for i in range(1, 9):\n",
    "    # Create a subplot with 2 rows and 4 columns, and set the current plot to the ith subplot\n",
    "    plt.subplot(2, 4, i)\n",
    "    \n",
    "    # Choose a random index from the validation set\n",
    "    rand_idx = random.randint(0, len(valid_images)-1)\n",
    "    \n",
    "    # Load the corresponding image from the file system using the image name from the validation set\n",
    "    image = cv2.imread(imagefolder+'/'+valid_data['image_name'].iloc[rand_idx])\n",
    "    \n",
    "    # Get the predicted bounding box coordinates and labels for the current image\n",
    "    (start_x, start_y, end_x, end_y) = box_pred[rand_idx]\n",
    "    pred_label = classes[np.argmax(label_pred[rand_idx])]\n",
    "    true_label = classes[np.argmax(valid_labels[rand_idx])]\n",
    "    \n",
    "    # Convert the predicted bounding box coordinates from normalized values to pixel values\n",
    "    start_x = int(start_x*image.shape[1])\n",
    "    start_y = int(start_y*image.shape[0])\n",
    "    end_x = int(end_x*image.shape[1])\n",
    "    end_y = int(end_y*image.shape[0])\n",
    "    \n",
    "    # Set the color of the bounding box to green if the predicted label matches the true label, and red otherwise\n",
    "    color = (0, 255, 0) if true_label==pred_label else (255, 0, 0)\n",
    "    \n",
    "    # Add the predicted label as text to the image, and draw the bounding box with the appropriate color\n",
    "    cv2.putText(image, pred_label, (start_x, start_y), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.5, (0, 255, 0), 2)\n",
    "    cv2.rectangle(image, (start_x, start_y), (end_x, end_y), color, 2)\n",
    "    \n",
    "    # Remove the tick marks from the x and y axes, and display the image\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
